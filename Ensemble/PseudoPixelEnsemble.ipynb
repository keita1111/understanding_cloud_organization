{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "For Pseudo Labellings<br>\n",
    " 1. hasMask==1<br>\n",
    "  -> average the mask-existing submission files by pixel<br>\n",
    " 2. hasMask==0<br>\n",
    "  -> Make score = NaN<br>\n",
    " 3. hasMask==unlabelled<br>\n",
    "  -> average all the submission files by pixel<br>\n",
    "  <br>\n",
    "  - Version101<br>\n",
    "  Erased Pixel Num Threshold Removal from Pseudo==1 Ensembles<br>\n",
    "  For (Fish,Flower,Gravel,Sugar)==(NaN,NaN,NaN,NaN)<br>\n",
    "   - if pseudo==1 availabe:<br>\n",
    "   -> GASSAN ensemble<br>\n",
    "   - elif pseudo==NaN exists:<br>\n",
    "   -> Choose the most Frequently notna() Cloud Type 'ALONE', to conduct a positive ensemble<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, time, random, warnings\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'PseudoPixelEnsemble_101'\n",
    "PATH = '../input'\n",
    "SUBMISSION_PATH = '../input/submissions'\n",
    "PSEUDO_VERSION = '7'\n",
    "REMOVE_THRESHOLD = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Show All Submission FIles & State the Files to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['submission_ResBase001.csv',\n",
       " 'submission_segmentation_and_classifier.csv',\n",
       " 'submission_Heng002_0.csv',\n",
       " 'submission_UNetEffb2_004_0.csv',\n",
       " 'submission_DSUNet106_0.csv',\n",
       " 'submission_UNetEffb2_004_9.csv',\n",
       " 'submission_Heng007_7.csv',\n",
       " 'submission_21model_keita.csv',\n",
       " 'submission_DSUNet104_0.csv',\n",
       " 'submission_Heng004_0.csv',\n",
       " 'submission_PseudoPixelEnsemble_101.csv',\n",
       " 'submission_UNetEffb2_004_12.csv',\n",
       " 'submission_UNetEffb2_006_0.csv',\n",
       " 'submission_pseudoPixelEnsemble_001.csv',\n",
       " 'submission_pseudo_001.csv',\n",
       " 'submission_PseudoPixelEnsemble_002.csv',\n",
       " 'submission_UNetEffb2_003_0.csv',\n",
       " 'submission_DSUNet103_0.csv',\n",
       " 'submission_Yirun_002_0.csv',\n",
       " 'submission_UNetEffb3_001_0.csv',\n",
       " 'submission_Heng006_0.csv',\n",
       " 'submission_UNetEffb2_008_0.csv',\n",
       " 'submission_UNetEffb2_005_0.csv',\n",
       " 'keita_ensemble_files',\n",
       " 'submission_UNetEffb2_007_0.csv',\n",
       " 'submission_Yirun_001_0.csv',\n",
       " 'submission_Heng003_0.csv',\n",
       " 'submission_UNetEffb2_002_0.csv',\n",
       " 'submission_Heng007_6.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'submission_Yirun_003_0.csv',\n",
       " 'submission_DSUNet107_9.csv',\n",
       " 'submission_DSUNet105_0.csv',\n",
       " 'submission_Heng005_0.csv',\n",
       " 'submission_Heng001_0.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['submission_eff-b4(CosineAnnealingLR)_0.6488.csv',\n",
       " 'submission_FPN(efficientb2)-ver1.0_0.6448.csv',\n",
       " 'submission_model_ensemble_0.6564.csv',\n",
       " 'submission_incepv2_0.658.csv',\n",
       " 'submission_effb2_0.658.csv',\n",
       " 'submission_FPN(efficientb2)-ver2_0.6463.csv',\n",
       " 'submission_DSUNet105_0_0.6480.csv',\n",
       " 'submission_Unet(efficientnet-b2)-ver1_0.6552.csv',\n",
       " 'submission_FPN(efficientb2)_0.6548.csv',\n",
       " 'submission_resnet101_attention_0.6513.csv',\n",
       " 'submission_unet_res101_0.6553.csv',\n",
       " 'submission_someensemble_0.6511.csv',\n",
       " 'submission_pixcel_0.6601.csv',\n",
       " 'submission_Unet(seresnet101)_0.6486.csv',\n",
       " 'submission_3Fold_0.6527.csv',\n",
       " 'submission_Unet(se_resnext50)_0.6513.csv',\n",
       " 'submission_UNetEffb2_004_0.6555.csv',\n",
       " 'submission_19model_ensemble_0.6624.csv',\n",
       " 'submission_efficientb5_0.6520.csv',\n",
       " 'submission_FPN(efficientb2)_0.6583.csv',\n",
       " 'submission_PSPNet(ResNet101)_0.6358.csv',\n",
       " 'submission_Linknet(efficientb2_AWS)_ver2_0.6490.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(SUBMISSION_PATH+'/keita_ensemble_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_files = [\n",
    "    '/submission_UNetEffb2_004_0.csv',\n",
    "    '/submission_21model_keita.csv',\n",
    "    '/submission_Heng005_0.csv',\n",
    "    '/submission_DSUNet105_0.csv',\n",
    "    '/keita_ensemble_files/submission_eff-b4(CosineAnnealingLR)_0.6488.csv',\n",
    "    '/keita_ensemble_files/submission_model_ensemble_0.6564.csv',\n",
    "    '/keita_ensemble_files/submission_incepv2_0.658.csv',\n",
    "    '/keita_ensemble_files/submission_pixcel_0.6601.csv',\n",
    "    '/keita_ensemble_files/submission_effb2_0.658.csv',\n",
    "    '/keita_ensemble_files/submission_resnet101_attention_0.6513.csv',\n",
    "    '/keita_ensemble_files/submission_19model_ensemble_0.6624.csv',\n",
    "    '/keita_ensemble_files/submission_FPN(efficientb2)_0.6583.csv',\n",
    "    '/keita_ensemble_files/submission_Linknet(efficientb2_AWS)_ver2_0.6490.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle: str = '', shape: tuple = (350, 525)):\n",
    "    '''\n",
    "    Decode rle encoded mask.\n",
    "    \n",
    "    :param mask_rle: run-length as string formatted (start length)\n",
    "    :param shape: (height, width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')\n",
    "\n",
    "def make_mask(label):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    masks = np.zeros((350, 525), dtype=np.float32)\n",
    "    if label is not np.nan:\n",
    "        mask = rle_decode(label)\n",
    "        masks[:, :] = mask\n",
    "            \n",
    "    return masks\n",
    "\n",
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    Convert mask to rle.\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \"\"\"\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pseudo Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002f507.jpg_Fish</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002f507.jpg_Flower</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002f507.jpg_Gravel</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002f507.jpg_Sugar</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0035ae9.jpg_Fish</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label EncodedPixels\n",
       "0    002f507.jpg_Fish           1 1\n",
       "1  002f507.jpg_Flower           1 1\n",
       "2  002f507.jpg_Gravel           1 1\n",
       "3   002f507.jpg_Sugar           1 1\n",
       "4    0035ae9.jpg_Fish           1 1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Submission\n",
    "sub_df = pd.read_csv('../input/sample_submission.csv')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# read all submission csv files\n",
    "submission_df_list = []\n",
    "for file in tqdm(use_files):\n",
    "    submission_df_list.append(pd.read_csv(SUBMISSION_PATH+file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [00:04<00:00, 244.50it/s]\n",
      "100%|██████████| 1195/1195 [00:05<00:00, 220.57it/s]\n",
      "100%|██████████| 1795/1795 [00:07<00:00, 238.71it/s]\n",
      "100%|██████████| 1247/1247 [00:05<00:00, 210.43it/s]\n",
      "100%|██████████| 736/736 [00:03<00:00, 233.46it/s]\n",
      "100%|██████████| 1304/1304 [00:05<00:00, 226.04it/s]\n",
      "100%|██████████| 558/558 [00:02<00:00, 238.71it/s]\n",
      "100%|██████████| 1920/1920 [00:07<00:00, 247.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002f507.jpg_Fish</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002f507.jpg_Flower</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002f507.jpg_Gravel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002f507.jpg_Sugar</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0035ae9.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label  flag\n",
       "0    002f507.jpg_Fish   0.0\n",
       "1  002f507.jpg_Flower   0.0\n",
       "2  002f507.jpg_Gravel   1.0\n",
       "3   002f507.jpg_Sugar   0.0\n",
       "4    0035ae9.jpg_Fish   NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Pseudo Label Files\n",
    "pseudo = sub_df[['Image_Label']].copy()\n",
    "for cloud_type in ['Fish', 'Flower', 'Gravel', 'Sugar']:\n",
    "    df = pd.read_csv(PATH + f'/pseudo/pseudo_{cloud_type}_ClassEffb0_{cloud_type}-{PSEUDO_VERSION}.csv')\n",
    "    df = df[df['from']=='test'].reset_index(drop=True)\n",
    "    \n",
    "    pseudo_image_labels = df[df['hasMask']==0]['path'].apply(lambda x: x.split('/')[-1] + '_' + cloud_type).to_numpy()\n",
    "    for im_lb in tqdm(pseudo_image_labels):\n",
    "        pseudo.loc[pseudo['Image_Label']==im_lb, 'flag'] = 0\n",
    "    \n",
    "    pseudo_image_labels = df[df['hasMask']==1]['path'].apply(lambda x: x.split('/')[-1] + '_' + cloud_type).to_numpy()\n",
    "    for im_lb in tqdm(pseudo_image_labels):\n",
    "        pseudo.loc[pseudo['Image_Label']==im_lb, 'flag'] = 1\n",
    "        pseudo_df = pd.DataFrame(pseudo_image_labels, columns=['Image_Label'])\n",
    "\n",
    "pseudo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ensemble Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f4c3b7898a4870b327d24fe79b1ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14792), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Starts Here\n",
    "\n",
    "submission = sub_df.copy()\n",
    "\n",
    "# if hasMask == 1.0\n",
    "def pseudo_positive_ensemble(encoded_pixel_list):\n",
    "    mask_list = []\n",
    "    for ep in encoded_pixel_list:\n",
    "        if ep==ep:\n",
    "            mask_list.append(make_mask(ep))\n",
    "    if len(mask_list) != 0:\n",
    "        mask = np.round(np.average(mask_list, axis=0))\n",
    "    else:\n",
    "        return np.nan\n",
    "    if mask.sum()!=0:\n",
    "        return mask2rle(mask)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# if hasMask == NaN\n",
    "def pseudo_nullified_ensemble(encoded_pixel_list):\n",
    "    mask_list = []\n",
    "    for ep in encoded_pixel_list:\n",
    "        mask_list.append(make_mask(ep))\n",
    "    if len(mask_list) != 0:\n",
    "        mask = np.round(np.average(mask_list, axis=0))\n",
    "        if np.count_nonzero(mask == 1) < REMOVE_THRESHOLD:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    if mask.sum()!=0:\n",
    "        return mask2rle(mask)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "##############################################\n",
    "# Ensemble with Pseudo Classification Labels #\n",
    "##############################################\n",
    "\n",
    "for im_lb in tqdm_notebook(submission['Image_Label'].to_numpy()):\n",
    "    \n",
    "    # make a list of EncodedPixels : String of each Submission FIles\n",
    "    encoded_pixel_list = []\n",
    "    for df in submission_df_list:\n",
    "        encoded_pixel_list.append(df[df['Image_Label']==im_lb]['EncodedPixels'].item())\n",
    "    \n",
    "    # Check the Pseudo Label for the certain Image_Label and work with Ensembling\n",
    "    pseudo_label = pseudo[pseudo['Image_Label']==im_lb]['flag'].item()\n",
    "    \n",
    "    if pseudo_label!=pseudo_label:# if NaN\n",
    "        pred = pseudo_nullified_ensemble(encoded_pixel_list)\n",
    "\n",
    "    elif pseudo_label==1.0:\n",
    "        pred = pseudo_positive_ensemble(encoded_pixel_list)\n",
    "        \n",
    "    elif pseudo_label==0.0:\n",
    "        pred = np.nan\n",
    "        \n",
    "    else:\n",
    "        print('Unknown Pseudo Label')\n",
    "        \n",
    "    # Submission CSV Maker\n",
    "    submission.loc[submission['Image_Label']==im_lb, 'EncodedPixels'] = pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3698/3698 [00:07<00:00, 500.51it/s]\n",
      "100%|██████████| 58/58 [00:04<00:00, 12.54it/s]\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Cover up (Fish,Flower,Gravel,Sugar)==(NaN,NaN,NaN,NaN) #\n",
    "##########################################################\n",
    "\n",
    "cloud_dict = {0:'Fish', 1:'Flower', 2:'Gravel', 3:'Sugar'}\n",
    "\n",
    "# GASSAN\n",
    "def pseudo_GASSAN_ensemble(encoded_pixel_list):\n",
    "    mask_list = []\n",
    "    for ep in encoded_pixel_list:\n",
    "        if ep==ep:\n",
    "            mask_list.append(make_mask(ep))\n",
    "    if len(mask_list) != 0:\n",
    "        mask = np.round(np.maximum(mask_list, axis=0)) # Taking the Maximums : Force all 1 to 1\n",
    "    else:\n",
    "        return np.nan\n",
    "    if mask.sum()!=0:\n",
    "        return mask2rle(mask)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "sub_copy = submission.copy()\n",
    "sub_copy['ImageID'] = sub_copy['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "pseudo['ImageID'] = pseudo['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Find out (Fish,Flower,Gravel,Sugar)==(NaN,NaN,NaN,NaN) ImageIDs\n",
    "cover_up_id_list = []\n",
    "for image_id in tqdm(sub_copy['ImageID'].unique()):\n",
    "    if sub_copy[sub_copy['ImageID']==image_id]['EncodedPixels'].count() == 0:\n",
    "        cover_up_id_list.append(image_id)\n",
    "        \n",
    "# Cover Up (Fish,Flower,Gravel,Sugar)==(NaN,NaN,NaN,NaN) ImageIDs\n",
    "for image_id in tqdm(cover_up_id_list):\n",
    "    \n",
    "    nan_type_list = []\n",
    "    nan_EncodingPixel_list = []\n",
    "    flag_one = 0\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        ps = pseudo[pseudo['ImageID']==image_id]['flag'].tolist()[i]\n",
    "\n",
    "        if ps == 1:\n",
    "            flag_one = 1 # if flag_one==1: skip the pseudo==NaN part\n",
    "            encoded_pixel_list = []\n",
    "            for df in submission_df_list:\n",
    "                encoded_pixel_list.append(df[df['Image_Label']==image_id+'_'+cloud_dict[i]]['EncodedPixels'].item())\n",
    "            ################### GASSAN ensemble for pseudo == 1\n",
    "            pred = pseudo_GASSAN_ensemble(encoded_pixel_list)\n",
    "            ###################\n",
    "            sub_copy.loc[sub_copy['Image_Label']==image_id+'_'+cloud_dict[i], 'EncodedPixels'] = pred\n",
    "\n",
    "        elif ps != ps: # if NaN\n",
    "            nan_type_list.append(cloud_dict[i])\n",
    "            encoded_pixel_list = []\n",
    "            for df in submission_df_list:\n",
    "                encoded_pixel_list.append(df[df['Image_Label']==im_lb]['EncodedPixels'].item())\n",
    "            nan_EncodingPixel_list.append(encoded_pixel_list)\n",
    "\n",
    "    if (flag_one == 0) & (len(nan_type_list) != 0):\n",
    "        count_list = []\n",
    "        count = 0\n",
    "        for i, eplist in enumerate(nan_EncodingPixel_list):\n",
    "            count_list.append(pd.Series(eplist).count())\n",
    "            if pd.Series(eplist).count() > count:\n",
    "                best_idx = i\n",
    "\n",
    "        if (np.array(count_list)==max(count_list)).sum() == 1:\n",
    "            ct = nan_type_list[best_idx] # Cloud Type which has the most notna() EncodedPixels 'ALONE'\n",
    "            encoded_pixel_list = []\n",
    "            for df in submission_df_list:\n",
    "                encoded_pixel_list.append(df[df['Image_Label']==image_id+'_'+ct]['EncodedPixels'].item())\n",
    "            ################### positive ensemble for pseudo == NaN & top count notna() Cloud Type\n",
    "            pred = pseudo_positive_ensemble(encoded_pixel_list)\n",
    "            ###################\n",
    "            sub_copy.loc[sub_copy['Image_Label']==image_id+'_'+cloud_dict[i], 'EncodedPixels'] = pred\n",
    "\n",
    "submission = sub_copy[['Image_Label', 'EncodedPixels']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002f507.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002f507.jpg_Flower</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002f507.jpg_Gravel</td>\n",
       "      <td>14 304 355 339 704 343 1053 345 1403 346 1752 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002f507.jpg_Sugar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0035ae9.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0035ae9.jpg_Flower</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0035ae9.jpg_Gravel</td>\n",
       "      <td>441 164 606 16 623 10 643 1 776 210 989 26 112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0035ae9.jpg_Sugar</td>\n",
       "      <td>1664 15 1721 7 2007 25 2057 22 2354 31 2396 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0038327.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0038327.jpg_Flower</td>\n",
       "      <td>130488 18 130832 27 131178 33 131525 38 131872...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label                                      EncodedPixels\n",
       "0    002f507.jpg_Fish                                                NaN\n",
       "1  002f507.jpg_Flower                                                NaN\n",
       "2  002f507.jpg_Gravel  14 304 355 339 704 343 1053 345 1403 346 1752 ...\n",
       "3   002f507.jpg_Sugar                                                NaN\n",
       "4    0035ae9.jpg_Fish                                                NaN\n",
       "5  0035ae9.jpg_Flower                                                NaN\n",
       "6  0035ae9.jpg_Gravel  441 164 606 16 623 10 643 1 776 210 989 26 112...\n",
       "7   0035ae9.jpg_Sugar  1664 15 1721 7 2007 25 2057 22 2354 31 2396 34...\n",
       "8    0038327.jpg_Fish                                                NaN\n",
       "9  0038327.jpg_Flower  130488 18 130832 27 131178 33 131525 38 131872..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv(SUBMISSION_PATH+f'/submission_{VERSION}.csv', index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
