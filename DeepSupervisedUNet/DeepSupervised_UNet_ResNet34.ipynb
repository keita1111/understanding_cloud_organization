{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Versions\n",
    " - DSUNet101<br>\n",
    " Baseline Model for Deep Supervised Learning<br>\n",
    " https://github.com/SeuTao/TGS-Salt-Identification-Challenge-2018-_4th_place_solution/blob/master/model/model.py<br>\n",
    " https://github.com/SeuTao/TGS-Salt-Identification-Challenge-2018-_4th_place_solution/blob/master/train.py<br>\n",
    " CV Score : , LB Score : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, cv2, time, random, warnings\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import ttach as tta\n",
    "\n",
    "import albumentations as albu\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 8\n",
    "SEED = 1234\n",
    "FOLD = 0\n",
    "VERSION = f'DSUNet101_{FOLD}'\n",
    "PATH = '../input'\n",
    "TRAIN_PATH = '../input/train_images_525/train_images_525'\n",
    "TEST_PATH = '../input/test_images_525/test_images_525' \n",
    "TRAIN_MASK_PATH = '../input/train_masks_525/train_masks_525'\n",
    "WEIGHT_PATH = '../input/weights'\n",
    "SUBMISSION_PATH = '../input/submissions'\n",
    "N_JOBS = 4\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "IMAGE_SIZE = (1400, 2100)\n",
    "IMAGE_SIZE_525 = (350, 525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_dict = {'Fish':1, 'Flower':2, 'Gravel':3, 'Sugar':4}\n",
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train_df['Class'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
    "train_df['class_id'] = train_df['Class'].map(class_names_dict)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../input/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n",
    "    '''\n",
    "    Decode rle encoded mask.\n",
    "    :param mask_rle: run-length as string formatted (start length)\n",
    "    :param shape: (height, width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')\n",
    "\n",
    "def make_mask_count(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    encoded_masks = df\n",
    "    masks = np.zeros((shape[0], shape[1]), dtype=np.float32)\n",
    "    if encoded_masks is np.nan:\n",
    "        masks = 0\n",
    "    else:\n",
    "        mask = rle_decode(encoded_masks)\n",
    "        masks[:, :] = mask\n",
    "        masks = np.sum(masks==1)\n",
    "    return masks\n",
    "\n",
    "train_df['pixel_count'] = train_df[\"EncodedPixels\"].apply(make_mask_count)\n",
    "train_df['pixel_group'] = train_df['pixel_count'].apply(lambda x: np.ceil(x/500000))\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()[['ImageId','pixel_group']]\n",
    "mask_count_df.sort_values('pixel_group', ascending=False, inplace=True)\n",
    "print(mask_count_df.shape)\n",
    "mask_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = mask_count_df.index.values\n",
    "\n",
    "li = [\n",
    "    [train_index, test_index]\n",
    "    for train_index, test_index in StratifiedKFold(\n",
    "        n_splits=N_SPLITS, shuffle=True, random_state=SEED\n",
    "    ).split(ids, mask_count_df[\"pixel_group\"])\n",
    "]\n",
    "\n",
    "train_idx, val_idx = ids[li[FOLD][0]], ids[li[FOLD][1]]\n",
    "train_ids = np.array(mask_count_df['ImageId'].iloc[train_idx])\n",
    "val_ids = np.array(mask_count_df['ImageId'].iloc[val_idx])\n",
    "test_ids = sub_df[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0]).drop_duplicates().values\n",
    "\n",
    "print(f\"train_length {len(train_idx)}\")\n",
    "print(f\"valid_length {len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_np(y_pred, y_true, smooth=1e-9, activation=False):\n",
    "    if activation:\n",
    "        y_pred = 1/(1 + np.exp(-y_pred))### sigmoid\n",
    "    y_pred = np.asarray(y_pred).astype(np.bool)\n",
    "    y_true = np.asarray(y_true).astype(np.bool)\n",
    "    if y_pred.shape != y_true.shape:\n",
    "        raise ValueError(\"Shape mismatch: y_pred and y_true must have the same shape.\")\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(y_pred, y_true)\n",
    "    return (2. * intersection.sum() + smooth) / (y_pred.sum() + y_true.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_no_threshold(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,\n",
    "    activation: bool = False\n",
    "):\n",
    "    if activation:\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    dice = 2 * intersection / (union + eps)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pr (torch.Tensor): A list of predicted elements\n",
    "        gt (torch.Tensor):  A list of elements that are to be predicted\n",
    "        eps (float): epsilon to avoid zero division\n",
    "        threshold: threshold for outputs binarization\n",
    "    Returns:\n",
    "        float: IoU (Jaccard) score\n",
    "    \"\"\"\n",
    "\n",
    "    if activation is None or activation == \"none\":\n",
    "        activation_fn = lambda x: x\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_fn = torch.nn.Sigmoid()\n",
    "    elif activation == \"softmax2d\":\n",
    "        activation_fn = torch.nn.Softmax2d()\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"Activation implemented for sigmoid and softmax2d\"\n",
    "        )\n",
    "\n",
    "    pr = activation_fn(pr)\n",
    "\n",
    "    if threshold is not None:\n",
    "        pr = (pr > threshold).float()\n",
    "\n",
    "    tp = torch.sum(gt * pr)\n",
    "    fp = torch.sum(pr) - tp\n",
    "    fn = torch.sum(gt) - tp\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + eps) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + eps)\n",
    "\n",
    "    return score\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    __name__ = 'dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid', beta=1.):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.eps = eps\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        return 1 - f_score(y_pr, y_gt, beta=self.beta, \n",
    "                           eps=self.eps, threshold=None, \n",
    "                           activation=self.activation)\n",
    "\n",
    "\n",
    "class BCEDiceLoss(DiceLoss):\n",
    "    __name__ = 'bce_dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid', beta=1., lambda_dice=1.0, lambda_bce=1.0):\n",
    "        super().__init__(eps, activation)\n",
    "        if activation == None:\n",
    "            self.bce = nn.BCELoss(reduction='mean')\n",
    "        else:\n",
    "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.lambda_dice=lambda_dice\n",
    "        self.lambda_bce=lambda_bce\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        dice = super().forward(y_pr, y_gt)\n",
    "        bce = self.bce(y_pr, y_gt)\n",
    "        return (self.lambda_dice*dice) + (self.lambda_bce* bce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-2, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        \n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "            \n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "        \n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(df: pd.DataFrame, image_name: str = \"img.jpg\", shape: tuple = IMAGE_SIZE_525):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "    df = df[df[\"ImageId\"] == image_name]\n",
    "    for idx, im_name in enumerate(df[\"ImageId\"].values):\n",
    "        for classidx, classid in enumerate([\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]):\n",
    "            mask = cv2.imread(f\"{PATH}/{TRAIN_MASK_PATH}/\"\n",
    "                + classid\n",
    "                + im_name\n",
    "            )\n",
    "            if mask is None:\n",
    "                continue\n",
    "            if mask[:, :, 0].shape != (350, 525):\n",
    "                mask = cv2.resize(mask, (525, 350))\n",
    "            masks[:, :, classidx] = mask[:, :, 0]\n",
    "    masks = masks / 255\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.Resize(320, 480),\n",
    "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "        albu.Rotate(limit=20,p=0.5),\n",
    "        albu.GaussNoise(p=0.2),        \n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.3, border_mode=0),\n",
    "        albu.GridDistortion(p=0.3),\n",
    "        albu.OpticalDistortion(p=0.2, distort_limit=2, shift_limit=0.5),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.Resize(320, 480),\n",
    "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#         albu.HorizontalFlip(p=0.5),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "def get_test_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.Resize(320, 480),\n",
    "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame = None,\n",
    "        datatype: str = \"train\",\n",
    "        img_ids: np.array = None,\n",
    "        transforms = albu.Compose([albu.Resize(320, 480)]),\n",
    "    ):\n",
    "        self.df = df\n",
    "        if datatype != \"test\":\n",
    "            self.data_folder = TRAIN_PATH\n",
    "        else:\n",
    "            self.data_folder = TEST_PATH\n",
    "        self.img_ids = img_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.img_ids[idx]\n",
    "        mask = make_mask(self.df, image_name)\n",
    "        image_path = os.path.join(self.data_folder, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = np.transpose(augmented[\"image\"], [2, 0, 1])\n",
    "        mask = np.transpose(augmented[\"mask\"], [2, 0, 1])\n",
    "        \n",
    "        is_empty = np.array([0., 0., 0., 0.])\n",
    "        for i in range(4):\n",
    "            if np.sum(mask[i])==0:\n",
    "                is_empty[i] = 1.\n",
    "                \n",
    "        return img, mask, is_empty\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = N_JOBS\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = CloudDataset(df=train_df,\n",
    "                             datatype=\"train\",\n",
    "                             img_ids=train_ids,\n",
    "                             transforms=get_training_augmentation(),)\n",
    "\n",
    "valid_dataset = CloudDataset(df=train_df,\n",
    "                             datatype=\"valid\",\n",
    "                             img_ids=val_ids,\n",
    "                             transforms=get_validation_augmentation(),)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=1, #batch_size\n",
    "                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,in_channels, channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, channels, kernel_size=3,padding=1),\n",
    "                                   nn.BatchNorm2d(channels),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(channels, out_channels, kernel_size=3,padding=1),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.SCSE = SCSEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x, e = None):\n",
    "        x = F.upsample(x, scale_factor=2, mode='bilinear')\n",
    "        if e is not None:\n",
    "            x = torch.cat([x,e],1)\n",
    "            x = F.dropout2d(x, p = 0.50)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.SCSE(x)\n",
    "        return x\n",
    "    \n",
    "class SCSEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SCSEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.channel_excitation = nn.Sequential(nn.Linear(channel, int(channel//reduction)),\n",
    "                                                nn.ReLU(inplace=True),\n",
    "                                                nn.Linear(int(channel//reduction), channel),\n",
    "                                                nn.Sigmoid())\n",
    "\n",
    "        self.spatial_se = nn.Sequential(nn.Conv2d(channel, 1, kernel_size=1,\n",
    "                                                  stride=1, padding=0, bias=False),\n",
    "                                        nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        bahs, chs, _, _ = x.size()\n",
    "\n",
    "        # Returns a new tensor with the same data as the self tensor but of a different size.\n",
    "        chn_se = self.avg_pool(x).view(bahs, chs)\n",
    "        chn_se = self.channel_excitation(chn_se).view(bahs, chs, 1, 1)\n",
    "        chn_se = torch.mul(x, chn_se)\n",
    "\n",
    "        spa_se = self.spatial_se(x)\n",
    "        spa_se = torch.mul(x, spa_se)\n",
    "        return torch.add(chn_se, 1, spa_se)\n",
    "    \n",
    "class model34_DeepSupervion(nn.Module):\n",
    "    def __init__(self, num_classes=1, image_size=(320, 480), mask_class = 2):\n",
    "        super(model34_DeepSupervion, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.encoder = torchvision.models.resnet34(pretrained=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1,\n",
    "                                   self.encoder.bn1,\n",
    "                                   self.encoder.relu)\n",
    "\n",
    "        self.conv2 = self.encoder.layer1\n",
    "        self.conv3 = self.encoder.layer2\n",
    "        self.conv4 = self.encoder.layer3\n",
    "        self.conv5 = self.encoder.layer4\n",
    "\n",
    "        self.center_global_pool = nn.AdaptiveAvgPool2d([1,1])\n",
    "        self.center_conv1x1 = nn.Conv2d(512, 64, kernel_size=1)\n",
    "        self.center_fc = nn.Sequential(nn.Linear(64, mask_class), \n",
    "                                       nn.Sigmoid())\n",
    "\n",
    "        self.center = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3,padding=1),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "\n",
    "        self.decoder5 = Decoder(256 + 512, 512, 64)\n",
    "        self.decoder4 = Decoder(64 + 256, 256, 64)\n",
    "        self.decoder3 = Decoder(64 + 128, 128, 64)\n",
    "        self.decoder2 = Decoder(64 + 64, 64, 64)\n",
    "        self.decoder1 = Decoder(64, 32, 64)\n",
    "\n",
    "        self.logits_no_empty = nn.Sequential(nn.Conv2d(320, 64, kernel_size=3, padding=1),\n",
    "                                             nn.ReLU(inplace=True),\n",
    "                                             nn.Conv2d(64, self.num_classes, kernel_size=1, padding=0), \n",
    "                                             nn.Sigmoid())\n",
    "\n",
    "        self.logits_final = nn.Sequential(nn.Conv2d(320+64, 64, kernel_size=3, padding=1),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Conv2d(64, self.num_classes, kernel_size=1, padding=0), \n",
    "                                          nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)     #1/4\n",
    "        conv2 = self.conv2(conv1) #1/4\n",
    "        conv3 = self.conv3(conv2) #1/8\n",
    "        conv4 = self.conv4(conv3) #1/16\n",
    "        conv5 = self.conv5(conv4) #1/32\n",
    "\n",
    "        center_512 = self.center_global_pool(conv5)\n",
    "        center_64 = self.center_conv1x1(center_512)\n",
    "        center_64_flatten = center_64.view(center_64.size(0), -1)\n",
    "        center_fc = self.center_fc(center_64_flatten)\n",
    "\n",
    "        f = self.center(conv5)\n",
    "        d5 = self.decoder5(f, conv5)\n",
    "        d4 = self.decoder4(d5, conv4)\n",
    "        d3 = self.decoder3(d4, conv3)\n",
    "        d2 = self.decoder2(d3, conv2)\n",
    "        d1 = self.decoder1(d2)\n",
    "\n",
    "        hypercol = torch.cat((\n",
    "            d1,\n",
    "            F.upsample(d2, scale_factor=2,mode='bilinear'),\n",
    "            F.upsample(d3, scale_factor=4, mode='bilinear'),\n",
    "            F.upsample(d4, scale_factor=8, mode='bilinear'),\n",
    "            F.upsample(d5, scale_factor=16, mode='bilinear')),1)\n",
    "        hypercol = F.dropout2d(hypercol, p = 0.50)\n",
    "\n",
    "        x_no_empty = self.logits_no_empty(hypercol)\n",
    "        hypercol_add_center = torch.cat((\n",
    "            hypercol,\n",
    "#             F.upsample(center_64, scale_factor=128,mode='bilinear')),1)\n",
    "            F.upsample(center_64, size=self.image_size, mode='bilinear')),1)\n",
    "\n",
    "        x_final = self.logits_final(hypercol_add_center)\n",
    "        return center_fc, x_no_empty, x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model34_DeepSupervion(num_classes=4, image_size=(320, 480), mask_class = 4)\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### todo\n",
    "criterion = BCEDiceLoss(eps=1e-9, activation='none', beta=1.0, lambda_dice=1.0, lambda_bce=1.0)\n",
    "optimizer = RAdam(model.parameters(), lr=0.004, weight_decay=0.0001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2, cooldown=2,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 20#### Due to Paperspace run hour limits\n",
    "\n",
    "train_loss_list = []\n",
    "train_dice_list = []\n",
    "valid_loss_list = []\n",
    "dice_score_list = []\n",
    "\n",
    "lr_rate_list = []\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "batch_multiplier = 8\n",
    "model.to(DEVICE)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    train_dice = 0.0\n",
    "    dice_score = 0.0\n",
    "    count = 0  #multiple minibatch\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    bar = tqdm_notebook(train_loader, postfix={\"train_loss\":0.0,\"train_dice\":0.0})\n",
    "    for (images, labels, is_empty) in bar:\n",
    "\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            images, labels, class_lbls = images.cuda(), labels.cuda(), torch.FloatTensor(is_empty.float()).cuda()\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        if count == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            count = batch_multiplier\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model   \n",
    "        binary_logits, no_empty_logits, final_logits = model(images)\n",
    "        \n",
    "        # calculate the batch loss\n",
    "        bce_loss_final = criterion(final_logits.reshape(-1), labels.reshape(-1))\n",
    "        class_loss = nn.BCELoss(reduction='mean')(binary_logits.reshape(-1), class_lbls.reshape(-1))\n",
    "        \n",
    "        non_empty = []\n",
    "        is_empty = class_lbls.reshape(-1)\n",
    "        for c in range(len(is_empty)):\n",
    "            if is_empty[c] == 0:\n",
    "                non_empty.append(c)\n",
    "                \n",
    "        has_empty_nonempty = False\n",
    "        if len(non_empty) * len(is_empty) > 0:\n",
    "            has_empty_nonempty = True\n",
    "\n",
    "        all_loss = bce_loss_final + 0.05 * class_loss\n",
    "        \n",
    "        if has_empty_nonempty:\n",
    "            indices = torch.LongTensor(non_empty).cuda()\n",
    "            y_non_empty = torch.index_select(no_empty_logits.reshape(-1,320,480), 0, indices)\n",
    "            mask_non_empty = torch.index_select(labels.reshape(-1,320,480), 0, indices)\n",
    "            loss_no_empty = criterion(y_non_empty.reshape(-1), mask_non_empty.reshape(-1))\n",
    "            all_loss += 0.50 * loss_no_empty\n",
    "\n",
    "        all_loss.backward()\n",
    "        \n",
    "        train_loss += all_loss.item() * images.size(0)\n",
    "        dice_cof    = dice_no_threshold(final_logits.reshape(-1).to(\"cpu\"), labels.reshape(-1).to(\"cpu\")).item()\n",
    "        train_dice += dice_cof * images.size(0)\n",
    "        \n",
    "        count -= 1  #multiple minibatch\n",
    "\n",
    "        bar.set_postfix(ordered_dict={\"train_loss\":all_loss.item(), \"train_dice\":dice_cof})\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    \n",
    "    del images, labels, is_empty\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        bar = tqdm_notebook(valid_loader, postfix={\"valid_loss\":0.0, \"dice_score\":0.0})\n",
    "        \n",
    "        for (images, labels, is_empty) in bar:\n",
    "            \n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                images, labels, class_lbls = images.cuda(), labels.cuda(), torch.FloatTensor(is_empty.float()).cuda()\n",
    "                \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "#             binary_logits, no_empty_logits, final_logits = tta.SegmentationTTAWrapper(model, \n",
    "#                                                                                       tta.aliases.d4_transform(), \n",
    "#                                                                                       merge_mode='mean')(images)\n",
    "            binary_logits, no_empty_logits, final_logits = model(images)\n",
    "            \n",
    "            # calculate the batch loss\n",
    "            bce_loss_final = criterion(final_logits.reshape(-1), labels.reshape(-1))\n",
    "            class_loss = nn.BCELoss(reduction='mean')(binary_logits.reshape(-1), class_lbls.reshape(-1))\n",
    "\n",
    "            non_empty = []\n",
    "            is_empty = class_lbls.reshape(-1)\n",
    "            for c in range(len(is_empty)):\n",
    "                if is_empty[c] == 0:\n",
    "                    non_empty.append(c)\n",
    "\n",
    "            has_empty_nonempty = False\n",
    "            if len(non_empty) * len(is_empty) > 0:\n",
    "                has_empty_nonempty = True\n",
    "\n",
    "            all_loss = bce_loss_final + 0.05 * class_loss\n",
    "\n",
    "            if has_empty_nonempty:\n",
    "                indices = torch.LongTensor(non_empty).cuda()\n",
    "                y_non_empty = torch.index_select(no_empty_logits.reshape(-1,320,480), 0, indices)\n",
    "                mask_non_empty = torch.index_select(labels.reshape(-1,320,480), 0, indices)\n",
    "                loss_no_empty = criterion(y_non_empty.reshape(-1), mask_non_empty.reshape(-1))\n",
    "                all_loss += 0.50 * loss_no_empty\n",
    "                \n",
    "            # update average validation loss \n",
    "            valid_loss += all_loss.item() * images.size(0)\n",
    "            dice_cof    = dice_no_threshold(final_logits.reshape(-1).to(\"cpu\"), labels.reshape(-1).to(\"cpu\")).item()\n",
    "            dice_score +=  dice_cof * images.size(0)\n",
    "            \n",
    "            bar.set_postfix(ordered_dict={\"valid_loss\":all_loss.item(), \"dice_score\":dice_cof})\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    train_dice = train_dice/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    dice_score = dice_score/len(valid_loader.dataset)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    train_dice_list.append(train_dice)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    dice_score_list.append(dice_score)\n",
    "\n",
    "    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} || Training Loss: {:.6f}  Training Dice Score: {:.6f} || Validation Loss: {:.6f} Dice Score: {:.6f}'.format(\n",
    "          epoch, train_loss, train_dice, valid_loss, dice_score))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), f\"{WEIGHT_PATH}/model_{VERSION}'_best.pth'\")\n",
    "        valid_loss_min = valid_loss\n",
    "    \n",
    "    scheduler.step(valid_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([i[0] for i in lr_rate_list])\n",
    "plt.ylabel('learing rate during training', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\n",
    "plt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\n",
    "plt.ylabel('loss', fontsize=22)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(dice_score_list)\n",
    "plt.ylabel('Dice score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"{WEIGHT_PATH}/model_{VERSION}'_best.pth'\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = N_JOBS\n",
    "batch_size = 1\n",
    "\n",
    "valid_dataset = CloudDataset(df=train_df,\n",
    "                             datatype=\"valid\",\n",
    "                             img_ids=val_ids,\n",
    "                             transforms=get_test_augmentation(),)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, \n",
    "                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import seaborn as sns\n",
    "\n",
    "def resize_it(x):\n",
    "    if x.shape != (350, 525):\n",
    "        x = cv2.resize(x, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "    return x\n",
    "\n",
    "def visualize_with_raw(\n",
    "    image, mask, original_image=None, original_mask=None, raw_image=None, raw_mask=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot image and masks.\n",
    "    If two pairs of images and masks are passes, show both.\n",
    "    \"\"\"\n",
    "    fontsize = 14\n",
    "    class_dict = {0: \"Fish\", 1: \"Flower\", 2: \"Gravel\", 3: \"Sugar\"}\n",
    "\n",
    "    f, ax = plt.subplots(3, 5, figsize=(24, 12))\n",
    "\n",
    "    ax[0, 0].imshow(original_image)\n",
    "    ax[0, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[0, i + 1].imshow(original_mask[:, :, i])\n",
    "        ax[0, i + 1].set_title(f\"Original mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "    ax[1, 0].imshow(raw_image)\n",
    "    ax[1, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[1, i + 1].imshow(raw_mask[:, :, i])\n",
    "        ax[1, i + 1].set_title(f\"Raw predicted mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "    ax[2, 0].imshow(image)\n",
    "    ax[2, 0].set_title(\"Transformed image\", fontsize=fontsize)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[2, i + 1].imshow(mask[:, :, i])\n",
    "        ax[2, i + 1].set_title(\n",
    "            f\"Predicted mask with processing {class_dict[i]}\", fontsize=fontsize\n",
    "        )\n",
    "        \n",
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    Convert mask to rle.\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \"\"\"\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    This is slightly different from other kernels as we draw convex hull here itself.\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    mask = (cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1])\n",
    "    mask = draw_convex_hull(mask.astype(np.uint8))\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((350, 525), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = component == c\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num\n",
    "\n",
    "def draw_convex_hull(mask, mode='convex'):\n",
    "    \n",
    "    img = np.zeros(mask.shape)\n",
    "    contours, hier = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        if mode=='rect': # simple rectangle\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
    "        if mode=='convex': # minimum convex hull\n",
    "            hull = cv2.convexHull(c)\n",
    "            cv2.drawContours(img, [hull], 0, (255, 255, 255),-1)\n",
    "        else: # minimum area rectangle\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(img, [box], 0, (255, 255, 255),-1)\n",
    "    return img/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_masks = []\n",
    "count = 0\n",
    "tr = min(len(val_ids)*4, 2220)\n",
    "probabilities = np.zeros((tr, 350, 525), dtype = np.float32)\n",
    "for data, target, _ in tqdm_notebook(valid_loader):\n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    target = target.cpu().detach().numpy()\n",
    "    _,_,pred_masks = model(data)\n",
    "    outpu = pred_masks.cpu().detach().numpy()\n",
    "    for p in range(data.shape[0]):\n",
    "        output, mask = outpu[p], target[p]\n",
    "        for m in mask:\n",
    "            valid_masks.append(resize_it(m))\n",
    "        for probability in output:\n",
    "            probabilities[count, :, :] = resize_it(probability)\n",
    "            count += 1\n",
    "        if count >= tr - 1:\n",
    "            break\n",
    "    if count >= tr - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_params = {}\n",
    "dice_scores = []\n",
    "for class_id in range(4):\n",
    "    print('-----------------------')\n",
    "    print([k for k, v in class_names_dict.items() if v == class_id + 1][0])\n",
    "    attempts = []\n",
    "    for t in tqdm_notebook(range(0, 100, 5)):\n",
    "        t /= 100\n",
    "        for ms in [5000, 10000, 15000, 20000, 30000]:\n",
    "            masks, d = [], []\n",
    "            for i in range(class_id, len(probabilities), 4):\n",
    "                probability = probabilities[i]\n",
    "                predict, num_predict = post_process(probability, t, ms)\n",
    "                masks.append(predict)\n",
    "            for i, j in zip(masks, valid_masks[class_id::4]):\n",
    "                if (i.sum() == 0) & (j.sum() == 0):\n",
    "                    d.append(1)\n",
    "                else:\n",
    "                    d.append(dice_coef_np(i, j))\n",
    "            attempts.append((t, ms, np.mean(d)))\n",
    "\n",
    "    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
    "    attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
    "    print(attempts_df.head())\n",
    "    best_threshold = attempts_df['threshold'].values[0]\n",
    "    best_size = attempts_df['size'].values[0]\n",
    "    dice_scores.append(attempts_df['dice'].values[0])\n",
    "    class_params[class_id] = (best_threshold, best_size)\n",
    "    \n",
    "print('-----------------------')\n",
    "print(class_params)\n",
    "print('-----------------------')\n",
    "print('Validation Score : ', np.mean(dice_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, target, _) in enumerate(valid_loader):\n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    _,_,pred_masks = model(data)\n",
    "    output = ((pred_masks)[0]).cpu().detach().numpy()\n",
    "    image  = data[0].cpu().detach().numpy()\n",
    "    mask   = target[0].cpu().detach().numpy()\n",
    "    output = output.transpose(1 ,2, 0)\n",
    "    image_vis = image.transpose(1, 2, 0)\n",
    "    mask = mask.astype('uint8').transpose(1, 2, 0)\n",
    "    pr_mask = np.zeros((350, 525, 4))\n",
    "    for j in range(4):\n",
    "        probability = resize_it(output[:, :, j])\n",
    "        pr_mask[:, :, j], _ = post_process(probability,\n",
    "                                           class_params[j][0],\n",
    "                                           class_params[j][1])\n",
    "    visualize_with_raw(image=image_vis, mask=pr_mask,\n",
    "                      original_image=image_vis, original_mask=mask,\n",
    "                      raw_image=image_vis, raw_mask=output)\n",
    "    if i >= 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_dataset = CloudDataset(df=sub_df,\n",
    "                            datatype='test', \n",
    "                            img_ids=test_ids,\n",
    "                            transforms=get_test_augmentation())\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                         shuffle=False, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "pathlist = [TEST_PATH+'/' + i.split(\"_\")[0] for i in subm['Image_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_mask(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (525,350))\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 0, 0], np.uint8)\n",
    "    upper = np.array([180, 255, 10], np.uint8)\n",
    "    return (~ (cv2.inRange(hsv, lower, upper) > 250)).astype(int)\n",
    "\n",
    "plt.imshow(get_black_mask(pathlist[120]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pixels = []\n",
    "image_id = 0\n",
    "cou = 0\n",
    "np_saved = 0\n",
    "for data, target, _ in tqdm_notebook(test_loader):\n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    _,_,output = model(data)\n",
    "    del data\n",
    "    for i, batch in enumerate(output):\n",
    "        for probability in batch:\n",
    "            probability = resize_it(probability.cpu().detach().numpy())\n",
    "            predict, num_predict = post_process(probability,\n",
    "                                                class_params[image_id % 4][0],\n",
    "                                                class_params[image_id % 4][1])\n",
    "            if num_predict == 0:\n",
    "                encoded_pixels.append('')\n",
    "            else:\n",
    "                black_mask = get_black_mask(pathlist[cou])\n",
    "                np_saved += np.sum(predict)\n",
    "                predict = np.multiply(predict, black_mask)\n",
    "                np_saved -= np.sum(predict)\n",
    "                r = mask2rle(predict)\n",
    "                encoded_pixels.append(r)\n",
    "            cou += 1\n",
    "            image_id += 1\n",
    "\n",
    "print(f\"number of pixel saved {np_saved}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['EncodedPixels'] = encoded_pixels\n",
    "sub_df.to_csv(SUBMISSION_PATH+f'/submission_{VERSION}.csv', columns=['Image_Label', 'EncodedPixels'], index=False)\n",
    "sub_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
